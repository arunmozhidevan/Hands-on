{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOgPHxZF9yCyOBBpsSSnjdu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunmozhidevan/Hands-on/blob/main/PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "brBW5gpn3swA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from sklearn.datasets import load_diabetes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Basics"
      ],
      "metadata": {
        "id": "Df0WG7MKxbfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creating an empty and random tensor"
      ],
      "metadata": {
        "id": "ljKnLtsNU0TW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.empty(2,2,2,2)"
      ],
      "metadata": {
        "id": "bWVX4Y2I361A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af9e5fcc-0e75-4add-d1a8-fc5527c44084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[6.6446e+23, 3.0634e-41],\n",
              "          [5.0447e-44, 0.0000e+00]],\n",
              "\n",
              "         [[       nan, 0.0000e+00],\n",
              "          [1.3235e-14, 3.6423e-06]]],\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.rand(2,2) # random 2x2 matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afqGGCEj94d8",
        "outputId": "1d1a88d1-8357-4f1d-e9c1-bf395d27e356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1968, 0.0646],\n",
              "        [0.8213, 0.6159]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros(2,2) # zero 2x2 matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8qe9BV597VS",
        "outputId": "b0646072-5260-460b-e309-e1619c2d5559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones(2,2)# 2x2 matrix of ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mea_CMRN9-7P",
        "outputId": "63aa3cba-ffec-4957-8ca1-7bb79ab8a4b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones(2,2, dtype=torch.int16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnZJnKvX-BPU",
        "outputId": "bdd0ce53-0f55-458c-b7c9-50c850c8df9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1],\n",
              "        [1, 1]], dtype=torch.int16)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones(2,2, requires_grad=True) # requires_grad - by default this will be true, if it's switched True it requires gradient while calculating "
      ],
      "metadata": {
        "id": "XXsDXKVmTv7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([2,2]), type(torch.tensor([2,2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeVIZgJY-Kda",
        "outputId": "6e912dc1-cbae-4240-82da-690cdeb029c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2, 2]), torch.Tensor)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = torch.rand(2,2), torch.rand(2,2)"
      ],
      "metadata": {
        "id": "YnCqHVBN-Nsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# slicing\n",
        "x = torch.rand(6,6)\n",
        "print(x) # orginal matrix\n",
        "print(x[1:3,1:3]) # sliced matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMIEcP97-hhM",
        "outputId": "dea877bf-8118-4a10-9ec9-a15f332b403f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2846, 0.9256, 0.7338, 0.9000, 0.9782, 0.8665],\n",
            "        [0.7942, 0.8119, 0.6378, 0.1246, 0.3377, 0.5770],\n",
            "        [0.0018, 0.0938, 0.1261, 0.0307, 0.2735, 0.8441],\n",
            "        [0.0804, 0.9723, 0.1766, 0.2326, 0.4107, 0.4854],\n",
            "        [0.6609, 0.6049, 0.7470, 0.4324, 0.3718, 0.3989],\n",
            "        [0.9984, 0.1094, 0.7216, 0.3985, 0.2536, 0.2307]])\n",
            "tensor([[0.8119, 0.6378],\n",
            "        [0.0938, 0.1261]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## slicing the tensor"
      ],
      "metadata": {
        "id": "WouSvjcTTjuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.view(-1,2) # if -1 is specified torch will compute on its own return approriate values based on the matirx size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjFhkQLd_MA2",
        "outputId": "1de4fcf9-1601-4c8d-be72-16215ca3f60e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2846, 0.9256],\n",
              "        [0.7338, 0.9000],\n",
              "        [0.9782, 0.8665],\n",
              "        [0.7942, 0.8119],\n",
              "        [0.6378, 0.1246],\n",
              "        [0.3377, 0.5770],\n",
              "        [0.0018, 0.0938],\n",
              "        [0.1261, 0.0307],\n",
              "        [0.2735, 0.8441],\n",
              "        [0.0804, 0.9723],\n",
              "        [0.1766, 0.2326],\n",
              "        [0.4107, 0.4854],\n",
              "        [0.6609, 0.6049],\n",
              "        [0.7470, 0.4324],\n",
              "        [0.3718, 0.3989],\n",
              "        [0.9984, 0.1094],\n",
              "        [0.7216, 0.3985],\n",
              "        [0.2536, 0.2307]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.view(36) # one dimention array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmto4MN1ALA7",
        "outputId": "b6dc5bd9-20bc-4507-8a59-69bf6138d7fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2846, 0.9256, 0.7338, 0.9000, 0.9782, 0.8665, 0.7942, 0.8119, 0.6378,\n",
              "        0.1246, 0.3377, 0.5770, 0.0018, 0.0938, 0.1261, 0.0307, 0.2735, 0.8441,\n",
              "        0.0804, 0.9723, 0.1766, 0.2326, 0.4107, 0.4854, 0.6609, 0.6049, 0.7470,\n",
              "        0.4324, 0.3718, 0.3989, 0.9984, 0.1094, 0.7216, 0.3985, 0.2536, 0.2307])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(5)"
      ],
      "metadata": {
        "id": "e5sIJsuMARSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Casting tensor to numpy"
      ],
      "metadata": {
        "id": "QyqB4A0tISZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a.numpy(), type(a.numpy()) #this will change into numpy array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgnrp4JQH2kg",
        "outputId": "2aaa33ed-8e21-46bc-aa90-d60aa474d43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 1., 1., 1., 1.], dtype=float32), numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Caution:** If both tensor(should be in gpu in case of gpu computaion) and numpy in the cpu then both will share memory.\n",
        "\n",
        "which means if you change/operate on one variable other variable also change due to share in memory"
      ],
      "metadata": {
        "id": "p3O2aGftH1Gt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Casting numpy to tensor "
      ],
      "metadata": {
        "id": "vhvkrUKxI4Y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = a.numpy()\n",
        "b, type(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcUs9ANOIxD1",
        "outputId": "f1fcd51f-a7cb-477b-8e56-31719cc2480e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 1., 1., 1., 1.], dtype=float32), numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.from_numpy(b) # to cast from array to tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_C77qrBI6Ga",
        "outputId": "e95cdde4-4fb6-46e5-e5ac-a8d453c2a7f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU processing in torch"
      ],
      "metadata": {
        "id": "zg_PeqFARWqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available() # to check the availablity of GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t13dH6GJQUE",
        "outputId": "efa97d13-76cd-49d3-f42b-52797e734a2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') # to run in cuda\n",
        "a_ = a.to(device)"
      ],
      "metadata": {
        "id": "Saet5Z3LScN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_ + a_ # this addition process is done in gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bot5JwKzSlF0",
        "outputId": "7be7b3db-20fb-49e9-cc4a-15de423b849e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2.], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To switch back to cpu processing"
      ],
      "metadata": {
        "id": "0jNHTylYTKRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to run in cpu\n",
        "a_.to('cpu')"
      ],
      "metadata": {
        "id": "XLIEaHcHSzU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd"
      ],
      "metadata": {
        "id": "ICROynFqVC-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## backward in autograd"
      ],
      "metadata": {
        "id": "P4zwNgxTxnSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.randn(3, requires_grad=True)\n",
        "x1 # 3 random tensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyGriKrVhpFn",
        "outputId": "439fa9e2-a192-461d-dcfc-58b29bb93b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0212, 0.6621, 1.5145], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = x1 + 2\n",
        "x2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYr0bANekSpM",
        "outputId": "7d680a3c-2c6e-4ebf-d955-53eccb8c3b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.0212, 2.6621, 3.5145], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x3 = x2*x2*2\n",
        "x3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2JyBoh1k9GU",
        "outputId": "cbabd3a7-dd66-4688-98f5-dacfb7340565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 8.1706, 14.1731, 24.7031], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x3 = x3.mean()\n",
        "x3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAs82HqdkY_2",
        "outputId": "b84faf6d-48b9-4a6e-c8ad-a8bd86d023c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(15.6823, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x3.backward() # dx3/dx1\n",
        "# vector jacobian product to get gradients\n",
        "x1.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXYYKW2KlRNJ",
        "outputId": "1fbad2e8-94c0-49af-d8b9-74dd5f65439e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.6950, 3.5494, 4.6860])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr/>"
      ],
      "metadata": {
        "id": "Iitb4BBhuTg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([2., 4., 6.], requires_grad=True)\n",
        "b = torch.tensor([3., 5., 7.], requires_grad=True) \n",
        "q = 3*a**2 - b**2"
      ],
      "metadata": {
        "id": "QBKunO9vJQNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ext_grad = torch.tensor([1., 1., 1.]) # if q is not scalar, we should send tensor as backward needs tensor\n",
        "q.backward(gradient=ext_grad)"
      ],
      "metadata": {
        "id": "kI6Ki9oDvUrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad == 6*a # differenciation of 3*a**2 is 6*a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu5H7d-pwZgx",
        "outputId": "fbc810dc-9419-44f9-f978-5b6889371373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad == -2*b # differenciation of b**2 is -2*b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUu8qA0Nw96l",
        "outputId": "060fa564-a93c-4e38-d1ad-fff302dd9e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr/>"
      ],
      "metadata": {
        "id": "GLQXjpDSuYgO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Different ways to set requires_grad = False after intialization"
      ],
      "metadata": {
        "id": "m_EONST8u77N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### requires_grad_"
      ],
      "metadata": {
        "id": "21zc6kfwyRoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([2., 4., 6.], requires_grad=True)\n",
        "a.requires_grad_(False) # sets gradient requires equals to false"
      ],
      "metadata": {
        "id": "X81njg5xhDsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### detach"
      ],
      "metadata": {
        "id": "XnnlVrsmyUDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([2., 4., 6.], requires_grad=True)\n",
        "a.detach() # sets gradient requires equals to false"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rqobke2rutnl",
        "outputId": "6cdcfaa8-c538-49a5-d20a-bc8609adecb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 4., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([2., 4., 6.], requires_grad=True)\n",
        "a.detach() # sets gradient requires equals to false"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-c-VEPyueoV",
        "outputId": "04dd0643-cbef-42c5-f159-87a3d9fb3c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 4., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### no_grad"
      ],
      "metadata": {
        "id": "acfWFeWfyati"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*With no_grad() function*"
      ],
      "metadata": {
        "id": "97D4iTKAvvHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([2., 4., 6.], requires_grad=True)\n",
        "with torch.no_grad(): # sets gradient requires equals to false the newer variable not the orginal\n",
        "  b = a + 2\n",
        "  print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ3QyQatvFd8",
        "outputId": "2e72cda0-2f9a-4a5d-94f5-2ed37e6f90f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4., 6., 8.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([2., 4., 6.], requires_grad=True)\n",
        "with torch.no_grad(): # sets gradient requires equals to false the newer variable not the orginal\n",
        "  print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--qww3pMvfNL",
        "outputId": "c5bc9f37-6410-44e1-d84b-e239176c0885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 4., 6.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"a\" still has requires_grad equals to \"True\""
      ],
      "metadata": {
        "id": "J6iLJhfRvhsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Without no_grad() function*"
      ],
      "metadata": {
        "id": "ttk9zmnCvzlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([2., 4., 6.], requires_grad=True)\n",
        "b = a + 2\n",
        "print(b) # gradients will be set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tsbfk1qKvhVe",
        "outputId": "c84c2906-cf3c-4329-ea34-749e67cf3de5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4., 6., 8.], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Incorrect gradients*"
      ],
      "metadata": {
        "id": "AyORK-6JBr8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "  model_output = (weights*3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqQJ7biNBne6",
        "outputId": "a318ad35-89e6-46ff-e9ea-4458bbc9150e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([6., 6., 6., 6.])\n",
            "tensor([9., 9., 9., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Correct gradients*"
      ],
      "metadata": {
        "id": "312AHOJnBwI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "  model_output = (weights*3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n",
        "  weights.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6XsJBqD6Mtl",
        "outputId": "bde4502c-9efd-44c2-db33-ad6b45773c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backpropagation"
      ],
      "metadata": {
        "id": "wG8HauObNcoZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## perceptron"
      ],
      "metadata": {
        "id": "z6XV1G7UaAhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "y_pred = x*w\n",
        "z = y_pred - y\n",
        "loss = z**2\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUi7UqSrNfrO",
        "outputId": "f66f68f6-28b6-45de-cf77-a6500219348d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1., grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "w.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjMDJTh4Xfdn",
        "outputId": "ebd0e3a8-adea-4a35-ecc4-b6da58bd0827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-2.)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## updating weights"
      ],
      "metadata": {
        "id": "Vg6vXNs1YIsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "for i in range(10):\n",
        "  print(f'Loss: {w}')\n",
        "  y_pred = x*w\n",
        "  z = y_pred - y\n",
        "  loss = z**2\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    w -= w.grad\n",
        "    w.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-LD8HHXYLFM",
        "outputId": "68f9e84f-3255-4af7-921a-01cfdf49808c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.0\n",
            "Loss: 3.0\n",
            "Loss: 1.0\n",
            "Loss: 3.0\n",
            "Loss: 1.0\n",
            "Loss: 3.0\n",
            "Loss: 1.0\n",
            "Loss: 3.0\n",
            "Loss: 1.0\n",
            "Loss: 3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent with autograd and backpropagation"
      ],
      "metadata": {
        "id": "CNqPLuPMPnKT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Fully Manual\n",
        "* Prediction - Manually\n",
        "* Gradient computation - Manually\n",
        "* loss computation - Manually\n",
        "* parameter updates - Manually"
      ],
      "metadata": {
        "id": "eLEk27WhFDfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# f = w * x\n",
        "# gradient = 2 * x * (y_pred - y)\n",
        "\n",
        "X = np.array([1,2,3,4], dtype= np.float32)\n",
        "Y = np.array([2,4,6,8], dtype= np.float32)\n",
        "w = 0.0"
      ],
      "metadata": {
        "id": "onxzAlLVlEpf"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "learning_rate = 0.01\n",
        "n_iters = 10"
      ],
      "metadata": {
        "id": "xhoT6tkPBO2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "def loss(y, y_pred):\n",
        "  return ((y_pred - y)**2).mean()\n",
        "\n",
        "def gradient(x, y, y_pred):\n",
        "  return np.dot(2*x, y_pred - y).mean()\n",
        "  \n",
        "# gradient\n",
        "# MSE = 1/N * (w*x - y)**2\n",
        "# dJ/dw = 1/N 2x (w*x -y)"
      ],
      "metadata": {
        "id": "ysHSh-gqlnBw"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f'Predicted before training: f(5) {forward(5):.3f}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YxKjC6yuvlWP",
        "outputId": "ba232228-2b10-4c2f-a806-74997307790c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Predicted before training: f(5) 0.000'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_iters):\n",
        "  # prediciton forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradient = backward pass\n",
        "  dw = gradient(X, Y, y_pred)\n",
        "\n",
        "  # update = weight\n",
        "  w-= learning_rate * dw\n",
        "\n",
        "  if epoch % 1 ==0:\n",
        "    print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.3f}')\n",
        "  \n",
        "print(f'Predicted after training: f(5) {forward(5):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Wrq3kKgzwhO",
        "outputId": "679bd50d-379c-46be-d03b-6534193d5155"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: w = 0.160, loss = 16.000\n",
            "epoch 2: w = 0.307, loss = 13.542\n",
            "epoch 3: w = 0.443, loss = 11.462\n",
            "epoch 4: w = 0.567, loss = 9.702\n",
            "epoch 5: w = 0.682, loss = 8.212\n",
            "epoch 6: w = 0.787, loss = 6.950\n",
            "epoch 7: w = 0.884, loss = 5.883\n",
            "epoch 8: w = 0.974, loss = 4.979\n",
            "epoch 9: w = 1.056, loss = 4.214\n",
            "epoch 10: w = 1.131, loss = 3.567\n",
            "Predicted after training: f(5) 5.656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# early stopping epoch when loss increases\n",
        "X = np.array([1,2,3,4], dtype= np.float32)\n",
        "Y = np.array([2,4,6,8], dtype= np.float32)\n",
        "w = 0.0\n",
        "\n",
        "prev_loss = 0\n",
        "epoch = 0\n",
        "while True:\n",
        "  epoch +=1\n",
        "  # prediciton forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradient = backward pass\n",
        "  dw = gradient(X, Y, y_pred)\n",
        "\n",
        "  # update = weight\n",
        "  w-= learning_rate * dw\n",
        "\n",
        "\n",
        "  print(f'epoch {epoch}: w = {w:.3f}, loss = {l:.3f}')\n",
        "  \n",
        "  if epoch == 1:\n",
        "    prev_loss = l\n",
        "    continue\n",
        "  if round(prev_loss,3) <= round(l,3):\n",
        "    break\n",
        "  prev_loss = l\n",
        "\n",
        "print(f'Predicted after training: f(5) {forward(5):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-GkdEsgDVfR",
        "outputId": "d2a68382-0818-4b29-f286-4437ecd6a313"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: w = 1.200, loss = 30.000\n",
            "epoch 2: w = 1.680, loss = 4.800\n",
            "epoch 3: w = 1.872, loss = 0.768\n",
            "epoch 4: w = 1.949, loss = 0.123\n",
            "epoch 5: w = 1.980, loss = 0.020\n",
            "epoch 6: w = 1.992, loss = 0.003\n",
            "epoch 7: w = 1.997, loss = 0.001\n",
            "epoch 8: w = 1.999, loss = 0.000\n",
            "epoch 9: w = 1.999, loss = 0.000\n",
            "Predicted after training: f(5) 9.997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Using autograd for Gradient computation\n",
        "* Prediction - Manually\n",
        "* Gradient computation - autograd\n",
        "* loss computation - Manually\n",
        "* parameter updates - Manually"
      ],
      "metadata": {
        "id": "CArVvQOBFa5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor(0.0, dtype= torch.float32, requires_grad= True)\n",
        "n_iters = 100"
      ],
      "metadata": {
        "id": "XoegCBLfGYc7"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_iters):\n",
        "  # prediciton = forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradient = backward pass\n",
        "  l.backward() # dl/dw\n",
        "\n",
        "  # update = weight\n",
        "  with torch.no_grad():\n",
        "    w-= learning_rate * w.grad\n",
        "\n",
        "    # zero gradients\n",
        "  w.grad.zero_()\n",
        "\n",
        "  if epoch % 5 ==0:\n",
        "    print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.3f}')\n",
        "  \n",
        "print(f'Predicted after training: f(5) {forward(5):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtw38-qXG_fx",
        "outputId": "fa80dc1b-c264-429c-9baa-912dddc51285"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: w = 0.300, loss = 30.000\n",
            "epoch 2: w = 0.555, loss = 21.675\n",
            "epoch 3: w = 0.772, loss = 15.660\n",
            "epoch 4: w = 0.956, loss = 11.314\n",
            "epoch 5: w = 1.113, loss = 8.175\n",
            "epoch 6: w = 1.246, loss = 5.906\n",
            "epoch 7: w = 1.359, loss = 4.267\n",
            "epoch 8: w = 1.455, loss = 3.083\n",
            "epoch 9: w = 1.537, loss = 2.228\n",
            "epoch 10: w = 1.606, loss = 1.609\n",
            "Predicted after training: f(5) 8.031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Pipeline: Model, Loss, and Optimizer"
      ],
      "metadata": {
        "id": "-rlEH8ifdhIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. PyTorch Loss & Optimer for loss computation and parameter updates\n",
        "* Prediction - Manually\n",
        "* Gradient computation - autograd\n",
        "* loss computation - PyTorch Loss\n",
        "* parameter updates - PyTorch Optimer"
      ],
      "metadata": {
        "id": "JgxUtM1VFbGT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Steps:*\n",
        "1. design mode (input, output size, forward pass)\n",
        "2. construct loss and optimizer\n",
        "3. training loop\n",
        "  - forward pass: compute prediction\n",
        "  - bacward pass: gradients\n",
        "  - update weights"
      ],
      "metadata": {
        "id": "k4NKl61AL1dK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD([w], lr = learning_rate)"
      ],
      "metadata": {
        "id": "unIGAjEvLpjg"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor(0.0, dtype= torch.float32, requires_grad= True)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  \n",
        "  y_pred = forward(X) # prediciton = forward pass\n",
        "\n",
        "  l = loss(Y, y_pred) # loss\n",
        "\n",
        "  l.backward() # gradient = backward pass, dl/dw\n",
        "\n",
        "  optimizer.step() # update = weight\n",
        "\n",
        "  optimizer.zero_grad() # zero gradients\n",
        "\n",
        "  if epoch % 5 ==0:\n",
        "    print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.3f}')\n",
        "  \n",
        "print(f'Predicted after training: f(5) {forward(5):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdT8CbbeJXSJ",
        "outputId": "c6931d17-7502-4356-9ce7-7ea740e85123"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: w = 0.300, loss = 30.000\n",
            "epoch 2: w = 0.555, loss = 21.675\n",
            "epoch 3: w = 0.772, loss = 15.660\n",
            "epoch 4: w = 0.956, loss = 11.314\n",
            "epoch 5: w = 1.113, loss = 8.175\n",
            "epoch 6: w = 1.246, loss = 5.906\n",
            "epoch 7: w = 1.359, loss = 4.267\n",
            "epoch 8: w = 1.455, loss = 3.083\n",
            "epoch 9: w = 1.537, loss = 2.228\n",
            "epoch 10: w = 1.606, loss = 1.609\n",
            "Predicted after training: f(5) 8.031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Fully PyTorch\n",
        "* Prediction - PyTorch Model\n",
        "* Gradient computation - autograd\n",
        "* loss computation - PyTorch Loss\n",
        "* parameter updates - PyTorch Optimer"
      ],
      "metadata": {
        "id": "MZSDHbb8FbPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.reshape(-1,1)\n",
        "Y = Y.reshape(-1,1)\n",
        "n_samples, n_features = X.shape\n",
        "input_size = n_features\n",
        "output_size = n_features"
      ],
      "metadata": {
        "id": "R1BHMMJaMi7S"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(input_size, output_size)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "1ljshCe5LlxF"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = torch.tensor([5], dtype= torch.float32)"
      ],
      "metadata": {
        "id": "ak2Lu-yoNTVZ"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f'Predicted after training: f(5) {model(X_test).item():.3f}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8su1_I5SM1Gp",
        "outputId": "5dd9edc2-f1fe-4c4d-b44e-84a2745a8433"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Predicted after training: f(5) 1.394'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_iters):\n",
        "  y_pred = model(X) # prediciton = forward pass\n",
        "  l = loss(Y, y_pred) # loss\n",
        "  l.backward() # gradient = backward pass, dl/dw \n",
        "  optimizer.step() # update = weight\n",
        "  optimizer.zero_grad() # zero gradients\n",
        "\n",
        "  if epoch % 5 ==0:\n",
        "    [w, b] = model.parameters()\n",
        "    print(f'epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.3f}')\n",
        "  \n",
        "print(f'Predicted after training: f(5) {model(X_test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1TgPYsCN2gk",
        "outputId": "72e4ac7b-af9a-4f89-c361-ff299f53c2f1"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: w = 0.070, loss = 29.788\n",
            "epoch 2: w = 0.319, loss = 20.757\n",
            "epoch 3: w = 0.527, loss = 14.489\n",
            "epoch 4: w = 0.700, loss = 10.140\n",
            "epoch 5: w = 0.844, loss = 7.122\n",
            "epoch 6: w = 0.965, loss = 5.027\n",
            "epoch 7: w = 1.065, loss = 3.573\n",
            "epoch 8: w = 1.149, loss = 2.563\n",
            "epoch 9: w = 1.219, loss = 1.862\n",
            "epoch 10: w = 1.278, loss = 1.375\n",
            "Predicted after training: f(5) 7.574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LinearRegression"
      ],
      "metadata": {
        "id": "OjrhN3a0PstX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom regression model"
      ],
      "metadata": {
        "id": "s470pr6QfFGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    # define layers\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.lin(x)"
      ],
      "metadata": {
        "id": "kMHJzO8-PwaJ"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegression(input_size, output_size)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "tmXk8Ig8QwVj"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_iters):\n",
        "  y_pred = model(X) # prediciton = forward pass\n",
        "  l = loss(Y, y_pred) # loss\n",
        "  l.backward() # gradient = backward pass, dl/dw \n",
        "  optimizer.step() # update = weight\n",
        "  optimizer.zero_grad() # zero gradients\n",
        "\n",
        "  if epoch % 5 ==0:\n",
        "    [w, b] = model.parameters()\n",
        "    print(f'epoch {epoch//5+1}: w = {w[0][0].item():.3f}, loss = {l:.3f}')\n",
        "  \n",
        "print(f'Predicted after training: f(5) {model(X_test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUa7c1FJQ21f",
        "outputId": "7b25a2f8-4137-44ac-e4c2-722139a0e072"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: w = -0.092, loss = 36.795\n",
            "epoch 2: w = 0.902, loss = 6.149\n",
            "epoch 3: w = 1.305, loss = 1.213\n",
            "epoch 4: w = 1.470, loss = 0.413\n",
            "epoch 5: w = 1.540, loss = 0.278\n",
            "epoch 6: w = 1.572, loss = 0.250\n",
            "epoch 7: w = 1.588, loss = 0.239\n",
            "epoch 8: w = 1.598, loss = 0.231\n",
            "epoch 9: w = 1.606, loss = 0.225\n",
            "epoch 10: w = 1.612, loss = 0.218\n",
            "epoch 11: w = 1.618, loss = 0.211\n",
            "epoch 12: w = 1.624, loss = 0.205\n",
            "epoch 13: w = 1.630, loss = 0.199\n",
            "epoch 14: w = 1.635, loss = 0.193\n",
            "epoch 15: w = 1.641, loss = 0.188\n",
            "epoch 16: w = 1.646, loss = 0.182\n",
            "epoch 17: w = 1.651, loss = 0.177\n",
            "epoch 18: w = 1.656, loss = 0.171\n",
            "epoch 19: w = 1.662, loss = 0.166\n",
            "epoch 20: w = 1.667, loss = 0.161\n",
            "Predicted after training: f(5) 9.321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression model on a dataset"
      ],
      "metadata": {
        "id": "NjAxuwHtfIIP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Steps:*\n",
        "1. design mode (input, output size, forward pass)\n",
        "2. construct loss and optimizer\n",
        "3. training loop\n",
        "  - forward pass: compute prediction\n",
        "  - bacward pass: gradients\n",
        "  - update weights"
      ],
      "metadata": {
        "id": "8kuPnNazjD76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "X_numpy, y_numpy = make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
        "X, Y = torch.tensor(X_numpy, dtype=torch.float32), torch.tensor(y_numpy, dtype=torch.float32).reshape(-1,1)\n",
        "n_samples, n_features = X.shape\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "V9ZJuuyOskEz"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(input_size, 1) # linear model takes, X feature size and y feature size\n",
        "loss = nn.MSELoss()  # MSE loss function takes y_prediction and y\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # stohastic gradient de"
      ],
      "metadata": {
        "id": "jBQlp2ach9sg"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_epochs = 10000\n",
        "for epoch in range(no_epochs):\n",
        "  y_pred = model(X) # forward pass\n",
        "  l = loss(y_pred, Y) # loss\n",
        "  l.backward() # backward pass\n",
        "  optimizer.step() # update = weight\n",
        "  optimizer.zero_grad() # zero gradients\n",
        "\n",
        "  print_steps = no_epochs // 10\n",
        "  if epoch % print_steps == 0:\n",
        "    [w, b] = model.parameters()\n",
        "    print(f'epoch: {epoch//print_steps+1}, loss = {l.item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI6MGPY7kPXt",
        "outputId": "0ecfa63d-cdc1-406f-fe04-4d3a44a7b317"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss = 5837.981\n",
            "epoch: 2, loss = 564.801\n",
            "epoch: 3, loss = 342.841\n",
            "epoch: 4, loss = 333.031\n",
            "epoch: 5, loss = 332.589\n",
            "epoch: 6, loss = 332.569\n",
            "epoch: 7, loss = 332.568\n",
            "epoch: 8, loss = 332.568\n",
            "epoch: 9, loss = 332.568\n",
            "epoch: 10, loss = 332.568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting regression line"
      ],
      "metadata": {
        "id": "hXUO-7alqFGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "fEq8-Ua5p6rc"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(X_numpy, y_numpy, 'b.')\n",
        "plt.plot(X_numpy,model(X).detach().numpy(),'r')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y', rotation=0)\n",
        "plt.title('Regression line')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ZKJH_vSpqAfc",
        "outputId": "0b3bc321-d081-4fff-94cd-4f080b143486"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data = load_diabetes()\n",
        "# X, Y = torch.tensor(data.data, dtype=torch.float32), torch.tensor(data.target, dtype=torch.float32).reshape(-1,1)\n",
        "# n_samples, n_features = X.shape\n",
        "# input_size = n_features\n",
        "# output_size = n_features\n",
        "# learning_rate = 0.01"
      ],
      "metadata": {
        "id": "o6o0lw9KfOKW"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LogiticRegression"
      ],
      "metadata": {
        "id": "1Y0bX9-iz-pW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer"
      ],
      "metadata": {
        "id": "y9YOIkO00Btv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## loading load_breast_cancer dataset"
      ],
      "metadata": {
        "id": "KK_yN3Tg4rZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cancer_data = load_breast_cancer()\n",
        "X, y  = cancer_data.data, cancer_data.target\n",
        "n_samples, n_features = X.shape\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "learning_rate = 0.01\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "w-B1luZy0YvW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## scaling the X_train and X_test"
      ],
      "metadata": {
        "id": "oOgyk_LR4w7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ss = StandardScaler()\n",
        "X_train_scaled = ss.fit_transform(X_train)\n",
        "X_test_scaled = ss.transform(X_test)"
      ],
      "metadata": {
        "id": "SPaLAqe01Muv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## casting numpy into tensor"
      ],
      "metadata": {
        "id": "G4ywW_S_447i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).reshape(-1,1)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).reshape(-1,1)"
      ],
      "metadata": {
        "id": "hsrEwPGS0--9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## custom logistic regression model"
      ],
      "metadata": {
        "id": "bVwqc7Cf47md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogiticRegression(nn.Module):\n",
        "\n",
        "  def __init__(self, n_input_features):\n",
        "    super(LogiticRegression, self).__init__()\n",
        "    # define layers\n",
        "    self.lin = nn.Linear(n_input_features, 1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    y_pred = torch.sigmoid(self.lin(x))\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "sobNoAhg1_Ul"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss and optimizer"
      ],
      "metadata": {
        "id": "Q3Mcbnh54_4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogiticRegression(n_features)\n",
        "loss = nn.BCELoss()  # MSE loss function takes y_prediction and y\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # stohastic gradient descent"
      ],
      "metadata": {
        "id": "k-xdW9Iw2u9F"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training the model"
      ],
      "metadata": {
        "id": "m1P0iU2d5B9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_epochs = 100\n",
        "for epoch in range(no_epochs):\n",
        "  y_pred = model(X_train_tensor) # forward pass\n",
        "  l = loss(y_pred, y_train_tensor) # loss\n",
        "  l.backward() # backward pass\n",
        "  optimizer.step() # update = weight\n",
        "  optimizer.zero_grad() # zero gradients\n",
        "\n",
        "  print_steps = no_epochs // 10\n",
        "  if epoch % print_steps == 0:\n",
        "    [w, b] = model.parameters()\n",
        "    print(f'epoch: {epoch//print_steps+1}, loss = {l.item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iynqvL4c3SPu",
        "outputId": "4efc6b59-9d5f-4768-b084-1bdffd116b4f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss = 0.973\n",
            "epoch: 2, loss = 0.703\n",
            "epoch: 3, loss = 0.554\n",
            "epoch: 4, loss = 0.466\n",
            "epoch: 5, loss = 0.409\n",
            "epoch: 6, loss = 0.368\n",
            "epoch: 7, loss = 0.337\n",
            "epoch: 8, loss = 0.314\n",
            "epoch: 9, loss = 0.295\n",
            "epoch: 10, loss = 0.279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## testing the model"
      ],
      "metadata": {
        "id": "2sGEnO0q5GWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  pred = model(X_test_tensor)\n",
        "  y_pred = pred.round()\n",
        "  acc = y_pred.eq(y_test_tensor).sum() / float(y_test_tensor.shape[0])\n",
        "  print(f'accuarcy: {acc:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzvdN4lS3nWb",
        "outputId": "704af1ed-4f43-4d2f-8aa5-dd001c768b42"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuarcy: 0.965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Training - Dataset and DataLoader  "
      ],
      "metadata": {
        "id": "5uY4RgMu5QRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "0cwzh9Mm5TpX"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUkdYcn48Cjo",
        "outputId": "ada3387a-ab18-4bdb-979d-42a03722c3ec"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-02 15:41:29--  https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10782 (11K) [application/x-httpd-php]\n",
            "Saving to: wine.data\n",
            "\n",
            "wine.data           100%[===================>]  10.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-02 15:41:30 (76.4 MB/s) - wine.data saved [10782/10782]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class winedataset(Dataset):\n",
        "  \n",
        "\n",
        "  def __init__(self):\n",
        "    data = np.loadtxt('/content/wine.data', delimiter=',', dtype=np.float32) # data loading\n",
        "    self.x = torch.from_numpy(data[:,1:]) # explanatory variables\n",
        "    self.y = torch.from_numpy(data[:,0]).reshape(-1,1) # first column contains the target variables\n",
        "    self.n_samples = data.shape[0] # no. of samples\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.y[index] # dataset\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples # len(dataset)"
      ],
      "metadata": {
        "id": "xvPv2TC-7FT0"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "dataset = winedataset()\n",
        "dataloader = DataLoader(dataset=dataset, batch_size=batch_size, num_workers=2)"
      ],
      "metadata": {
        "id": "xug9gA4G-vCK"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(dataloader)\n",
        "data = dataiter.next()\n",
        "features, labels = data"
      ],
      "metadata": {
        "id": "s1kV2QYe-9Wk"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = int(np.ceil((total_samples/batch_size)))"
      ],
      "metadata": {
        "id": "R0R58hHyALwy"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for i, (inputs, labels) in enumerate(dataloader):\n",
        "    if (i+1) % 5 ==0:\n",
        "      print(f'epoch: {epoch+1}/{num_epochs}, step: {i+1: =2}/{n_iterations}, input: {inputs.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b919EbitBh8z",
        "outputId": "7f3b12fa-c49a-46f5-f4bb-4658ded1ace9"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1/2, step:  5/45, input: torch.Size([4, 13])\n",
            "epoch: 1/2, step: 10/45, input: torch.Size([4, 13])\n",
            "epoch: 1/2, step: 15/45, input: torch.Size([4, 13])\n",
            "epoch: 1/2, step: 20/45, input: torch.Size([4, 13])\n",
            "epoch: 1/2, step: 25/45, input: torch.Size([4, 13])\n",
            "epoch: 1/2, step: 30/45, input: torch.Size([4, 13])\n",
            "epoch: 1/2, step: 35/45, input: torch.Size([4, 13])\n",
            "epoch: 1/2, step: 40/45, input: torch.Size([4, 13])\n",
            "epoch: 1/2, step: 45/45, input: torch.Size([2, 13])\n",
            "epoch: 2/2, step:  5/45, input: torch.Size([4, 13])\n",
            "epoch: 2/2, step: 10/45, input: torch.Size([4, 13])\n",
            "epoch: 2/2, step: 15/45, input: torch.Size([4, 13])\n",
            "epoch: 2/2, step: 20/45, input: torch.Size([4, 13])\n",
            "epoch: 2/2, step: 25/45, input: torch.Size([4, 13])\n",
            "epoch: 2/2, step: 30/45, input: torch.Size([4, 13])\n",
            "epoch: 2/2, step: 35/45, input: torch.Size([4, 13])\n",
            "epoch: 2/2, step: 40/45, input: torch.Size([4, 13])\n",
            "epoch: 2/2, step: 45/45, input: torch.Size([2, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = dataset[0]\n",
        "x, y = np.array(x), np.array(y)"
      ],
      "metadata": {
        "id": "VOXuoGoyRI4Y"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ToTensor([x, y])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ud_S6SkRLQm",
        "outputId": "7a9ab998-b38d-4bd2-e1a8-18e04860dfae"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
              "         3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
              "         1.0650e+03]), tensor([1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Transforms"
      ],
      "metadata": {
        "id": "yZ-hW7M-RkOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class winedataset(Dataset):\n",
        "  \n",
        "\n",
        "  def __init__(self, transformer = None):\n",
        "    data = np.loadtxt('/content/wine.data', delimiter=',', dtype=np.float32) # data loading\n",
        "    \n",
        "    # here the inputs are of numpy\n",
        "    self.x = np.array(data[:,1:]) # explanatory variables\n",
        "    self.y = np.array(data[:,[0]]) # first column contains the target variables\n",
        "    self.n_samples = data.shape[0] # no. of samples\n",
        "\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    samples = self.x[index], self.y[index] # dataset\\\n",
        "\n",
        "    if self.transformer:\n",
        "      samples = self.transformer(samples)\n",
        "\n",
        "    return samples\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples # len(dataset)"
      ],
      "metadata": {
        "id": "Il0wwVIuRilT"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToTensor:\n",
        "  def __call__(self, sample):\n",
        "    inputs, targets = sample\n",
        "    return torch.from_numpy(inputs), torch.from_numpy(targets)"
      ],
      "metadata": {
        "id": "uhH6-jHWIUsm"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without Tensor Transform"
      ],
      "metadata": {
        "id": "OYfZF69-X-gJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = winedataset()\n",
        "dataset[0] # the values are of numpy not tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwtgUh5rX2Sm",
        "outputId": "29219a9a-46b2-4492-9eaa-8ffbbf3f6215"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.423e+01, 1.710e+00, 2.430e+00, 1.560e+01, 1.270e+02, 2.800e+00,\n",
              "        3.060e+00, 2.800e-01, 2.290e+00, 5.640e+00, 1.040e+00, 3.920e+00,\n",
              "        1.065e+03], dtype=float32), array([1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With Tensor Transform"
      ],
      "metadata": {
        "id": "PAqtM_zaX4SB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = winedataset(transformer=ToTensor)\n",
        "dataset[0] # the values are of tensor not numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQN4-ToDHNB-",
        "outputId": "3372a855-018e-44b1-dc39-e9b8af3238bb"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
              "         3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
              "         1.0650e+03]), tensor([1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With Tensor and Multiplication Transform"
      ],
      "metadata": {
        "id": "3LvcnOz4ShXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Multransform:\n",
        "\n",
        "  def __init__(self, factor):\n",
        "    self.factor = factor\n",
        "\n",
        "  def __call__(self, sample):\n",
        "    inputs, targets = sample\n",
        "    inputs *= self.factor\n",
        "    return inputs, targets"
      ],
      "metadata": {
        "id": "jFVHoJSsUVWd"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "composed = torchvision.transforms.Compose([ToTensor(), Multransform(4)])\n",
        "dataset = winedataset(transformer=composed)\n",
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDnxbYe_Xzwl",
        "outputId": "7766874c-59c7-428c-affb-7cc0691094bf"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([5.6920e+01, 6.8400e+00, 9.7200e+00, 6.2400e+01, 5.0800e+02, 1.1200e+01,\n",
              "         1.2240e+01, 1.1200e+00, 9.1600e+00, 2.2560e+01, 4.1600e+00, 1.5680e+01,\n",
              "         4.2600e+03]), tensor([1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Softmax and Cross Entropy"
      ],
      "metadata": {
        "id": "nu9wPHmiZYJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.random.choice(10,4)"
      ],
      "metadata": {
        "id": "gAXNzk9iaIw7"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhLF9tsXaOml",
        "outputId": "1938b69e-7745-4a43-d653-06bd014bdc86"
      },
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 1, 9, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exp_y = [np.exp(i) for i in y]\n",
        "exp_y_sum = sum(exp_y)"
      ],
      "metadata": {
        "id": "hQtm66hAaUJy"
      },
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGE6OqbYbV7m",
        "outputId": "490da62b-feec-4270-e01c-bfee781bb0ed"
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[403.4287934927351, 2.718281828459045, 8103.083927575384, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[i/exp_y_sum for i in exp_y]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch294od3aqMW",
        "outputId": "81a08a06-3202-4a96-a381-78c7d4d5dfd8"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04740515191131972,\n",
              " 0.0003194134010620674,\n",
              " 0.9521579290641328,\n",
              " 0.00011750562348538315]"
            ]
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[i/sum(y) for i in y]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU9BH4vUa7Rd",
        "outputId": "8fec74b3-0190-4053-eb4a-d73c8201108f"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.375, 0.0625, 0.5625, 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notes"
      ],
      "metadata": {
        "id": "ol0RuosYzP7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* if a function ends **_** , that basically will modify our variable inplace\n",
        "\n",
        "* **grad.zero_()** for every mini-batch during the training phase, we typically want to explicitly set the gradients to zero before starting to do backpropragation (i.e., updating the Weights and biases) because PyTorch accumulates the gradients on subsequent backward passes.\n",
        "\n",
        "* **epoch** is 1 forward and backward pass of all training samples\n",
        "\n",
        "* **batch_size** is number of training samples in one forward and backward pass\n",
        "\n",
        "* **no. of iterations** is no. passes, each pass using [batch_size] no. of samples <br> e.g.<br>*samples = 100*<br>*batch_size* = 20<br>samples/batch_size = 5 *iterations* for *1 epoch*"
      ],
      "metadata": {
        "id": "SXZq3W8jzOAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference"
      ],
      "metadata": {
        "id": "vMnJ3CrCzeRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Youtube Tutorials<br>\n",
        "https://www.youtube.com/watch?v=EMXfZB8FVUA&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=1"
      ],
      "metadata": {
        "id": "c-0ODAL_zjrh"
      }
    }
  ]
}